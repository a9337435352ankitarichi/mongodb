{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Data With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import The Pandas And Numpy Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set Pandas display options so we can see more data\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Two Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path of the data\n",
    "# Change this to the full path of the data files\n",
    "base_file_path = '/Users/robertdempsey/Dropbox/Private/Python Business Intelligence Cookbook/Data/Stats19-Data1979-2004/'\n",
    "\n",
    "accidents_data_file = 'Accidents7904.csv'\n",
    "casualty_data_file = 'Casualty7904.csv'\n",
    "vehicles_data_file = 'Vehicles7904.csv'\n",
    "vehicle_types_file = 'vehicle_types.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the acidents dataset into a pandas dataset using the 'Accident_Index' column as the index of the dataframe\n",
    "af = base_file_path + accidents_data_file\n",
    "accidents = pd.read_csv(af,\n",
    "                        sep=',',\n",
    "                        header=0,\n",
    "                        index_col=0,\n",
    "                        parse_dates=False,\n",
    "                        tupleize_cols=False,\n",
    "                        error_bad_lines=False,\n",
    "                        warn_bad_lines=False,\n",
    "                        skip_blank_lines=True,\n",
    "                        nrows=1000\n",
    "                        )\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the casualties dataset into a pandas dataset using the 'Acc_Index' column as the index of the dataframe\n",
    "cf = base_file_path + casualty_data_file\n",
    "casualties = pd.read_csv(cf,\n",
    "                        sep=',',\n",
    "                        header=0,\n",
    "                        index_col=0,\n",
    "                        parse_dates=False,\n",
    "                        tupleize_cols=False,\n",
    "                        error_bad_lines=False,\n",
    "                        warn_bad_lines=False,\n",
    "                        skip_blank_lines=True,\n",
    "                        nrows=1000\n",
    "                        )\n",
    "casualties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets using a left join, like in SQL, based on the index values, which in this case is the accident_index\n",
    "merged_data = pd.merge(accidents, casualties, how = 'left', left_index = True, right_index = True)\n",
    "merged_data.head()\n",
    "\n",
    "# Uncomment the following lines to create a CSV file of the merged data\n",
    "# merged_data.to_csv('merged_dataset.csv', sep=',', encoding='utf-8')\n",
    "# print(\"CSV creation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reformat data: uppercase a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to use for the following examples\n",
    "# All data created using the Faker library: https://github.com/joke2k/faker\n",
    "lc = pd.DataFrame({'people' : [\"cole o'brien\", \"lise heidenreich\", \"zilpha skiles\", \"damion wisozk\"],\n",
    "                   'age' : [24, 35, 46, 57],\n",
    "                   'ssn': ['6439', '689 24 9939', '306-05-2792', '992245832'],\n",
    "                   'birth_date': ['2/15/54', '05/07/1958', '19XX-10-23', '01/26/0056'],\n",
    "                   'customer_loyalty_level' : ['not at all', 'moderate', 'moderate', 'highly loyal']})\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to uppercase a string\n",
    "def uppercase_string(s):\n",
    "    \"\"\"\n",
    "    Standardizes a string by making it all caps\n",
    "    :param s: string to uppercase\n",
    "    :return: s\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = s.upper()\n",
    "    except:\n",
    "        pass\n",
    "    return s\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "lc.customer_loyalty_level = lc.customer_loyalty_level.apply(uppercase_string)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titlecase anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this code, install the titlecase library: pip install titlecase\n",
    "from titlecase import titlecase\n",
    "\n",
    "def titlecase_anything(thing):\n",
    "    \"\"\"\n",
    "    Uses the titlecase library to titlecase a string\n",
    "    :param thing: the thing to titlecase\n",
    "    :return: thing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        thing = titlecase(thing)\n",
    "    except:\n",
    "        pass\n",
    "    return thing\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "lc.people = lc.people.apply(titlecase_anything)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Update values in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with no data\n",
    "lc['marketing_score'] = np.nan\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing data of the chosen column with the text 'Missing', in place using inplace=True\n",
    "# If we didn't use the inplace argument our update wouldn't stay\n",
    "lc.marketing_score.fillna(0, inplace=True)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standardize a social security number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right(s, amount):\n",
    "    \"\"\"\n",
    "    Returns a specified number of characters from a string starting on the right side\n",
    "    :param s: string to extract the characters from\n",
    "    :param amount: the number of characters to extract from the string\n",
    "    \"\"\"\n",
    "    return s[-amount:]\n",
    "\n",
    "def standardize_ssn(ssn):\n",
    "    \"\"\"\n",
    "    Standardizes the SSN by removing any spaces, \"XXXX\", and dashes\n",
    "    :param ssn: ssn to standardize\n",
    "    :return: formatted_ssn\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ssn = ssn.replace(\"-\",\"\")\n",
    "        ssn = \"\".join(ssn.split())\n",
    "        if len(ssn) < 9 and ssn != 'Missing':\n",
    "            ssn = \"000000000\" + ssn\n",
    "            ssn = right(ssn, 9)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ssn\n",
    "\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "lc.ssn = lc.ssn.apply(standardize_ssn)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standardize dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "from datetime import datetime\n",
    "\n",
    "def standardize_date(the_date):\n",
    "    \"\"\"\n",
    "    Standardizes a date\n",
    "    :param the_date: the date to standardize\n",
    "    :return formatted_date\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert what we have to a string, just in case\n",
    "    the_date = str(the_date)\n",
    "    \n",
    "    # Handle missing dates, however pandas should have filled this in as missing\n",
    "    if not the_date or the_date.lower() == \"missing\" or the_date == \"nan\":\n",
    "        formatted_date = \"MISSING\"\n",
    "\n",
    "    # Handle dates that end with 'XXXX', start with 'XX', or are less than 1900\n",
    "    if the_date.lower().find('x') != -1:\n",
    "        formatted_date = \"Incomplete\"\n",
    "\n",
    "    # Handle dates that start with something like \"0056\"\n",
    "    if the_date[0:2] == \"00\":\n",
    "        formatted_date = the_date.replace(\"00\", \"19\")\n",
    "\n",
    "    # 03/03/15\n",
    "    try:\n",
    "        formatted_date = str(datetime.strptime(the_date, '%m/%d/%y').strftime('%m/%d/%y'))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 03/03/2015\n",
    "    try:\n",
    "        formatted_date = str(datetime.strptime(the_date, '%m/%d/%Y').strftime('%m/%d/%y'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 0000-03-03\n",
    "    try:\n",
    "        if int(the_date[0:4]) < 1900:\n",
    "            formatted_date = \"Incomplete\"\n",
    "        else:\n",
    "            formatted_date = str(datetime.strptime(the_date, '%Y-%m-%d').strftime('%m/%d/%y'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return formatted_date\n",
    "\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "lc.birth_date = lc.birth_date.apply(standardize_date)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert categories to numbers for a speed boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the customer_loyalty_level categories to numerics for faster processing\n",
    "lc.customer_loyalty_level = lc.customer_loyalty_level.astype('category')\n",
    "lc.customer_loyalty_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data types after the conversion of the customer_loyalty_level column\n",
    "lc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can describe the newly converted column\n",
    "lc.customer_loyalty_level.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
